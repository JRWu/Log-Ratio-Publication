\documentclass[titlepage]{article}
\usepackage[margin=1in]{geometry}
	\geometry{letterpaper}
\usepackage{subcaption}
\usepackage{biblatex}
	\addbibresource{references.bib}
\usepackage{amsmath} 
\usepackage{hyperref}
\usepackage{float}

\title{INSERT\_TITILE\_HERE}
\author{Jia Rong Wu, Dr. Gregory Gloor}
\date{\today}

\begin{document}
\maketitle

\section{Abstract}

High throughput sequencing technology can be leveraged to obtain information ranging from transcription profiles, microbial diversity, and even the relative abundance of cellular cultures. However, many experimental tools inappropriately treat the underlying features in sequencing data as counts when they should be considered compositions. This paper proposes a log-ratio transformation method that allows for feature comparisons between samples using a non-deterministic geometric mean. The log-ratio transformation will be implemented as an extension to a compositional data analysis tool known as ALDEx2 or ANOVA Like Differential Expression. It will be demonstrated using both simulated and real data that (insert log-ratio transformation name here) provides a result that is more robust and in line with expectations relative to ALDEx2.


While the focus of this paper is RNA-seq and its analysis, the concepts of compositional data analysis are generalizable to any experimental design that utilizes high throughput sequencing.

While this paper discusses high throughput sequencing through RNA-seq, the concepts are generalizable to any experimental design that utilizes high throughput sequencing 



\section{Background}

RNA-Seq is one of many tools that uses high throughput sequencing technology in order to generate information regarding the transcriptome of an organism. Transcriptomics, or expression profiling, is the study of one or many sets of RNA transcripts expressed under a given condition. Differential expression analysis of RNA-Seq data is the process of identifying transcripts or features that are differentially expressed between conditions. Traditional approaches for RNA-Seq data analysis treat the data as counts per feature, and apply statistical tests on these counts. ALDEx2 treats RNA-Seq data as compositions and infers differential expression from both statistical significance and effect sizes. 

Count based data for RNA-Seq must fit the assumption that it is independent and identically distributed for statistical tests \cite{auer2010, mcdonald2014}. However, in the context of RNA-Seq, counts per feature are not independent in the sense that they are dependent on the sequencing capacity of the machine. The probability of detecting rare transcripts in RNA-Seq is lower in the presence of highly expressed transcripts \cite{tarazona2011}. Absolute feature counts returned from a sequencing machine are uninformative due to the violation of the assumption of independence. Thus, RNA-Seq data is inherently compositional and must be treated as such. Traditional tools do not address the compositional nature of RNA-seq data \cite{fernandes2014}.

Formally, a composition is defined as a vector whose components are proportions. These proportions sum to an arbitrary constrained constant \textit{c}. This constant \textit{c} is arbitrary in the sense that it can represent 1 if the components are proportions, 100 if the components are percentages or other constants such as 10\textsuperscript{9} for parts-per-billion. Absolute values of components in a composition are uninformative. The only information provided in compositional data is the relative magnitudes of the components ratios between all pairs of components \cite{aitchison1986}. As compositional data carries relative information between components, analyzing the data as log-ratios is suggested by Aitchison \cite{aitchison1986}. The scale-invariant Centered-Log-Ratio (CLR) transformation proposed by Aitchison is defined as: 

\begin{equation}
\begin{split}
y &= \{   \frac{x_i}{g(x)}   \}_{i=1,\dots,D} \\
\text{where}~
	y &= \text{A composition transformed by CLR} \\
	x &= \text{A component of the non-transformed composition (x)} \\
	D &= \text{The number of components of x} \\ 
	g(x) &= \text{Geometric mean of D components of x}
\end{split}
\label{eq:CLR}
\end{equation}

For a given sample, ALDEx2 considers the sample to be a composition, and its features to be the components \cite{fernandes2014}. For each feature in a sample, ALDEx2 converts its count into a set of probabilities through Monte Carlo sampling from the Dirichlet Distribution. Monte Carlo methods are defined as repeated random sampling from a probability distribution.  Sampling features as Monte-Carlo instances from a Dirichlet distribution allows for sampling variance to be modeled \cite{fernandes2013}. Furthermore, the sum of each instance per sample is equivalent to one, making the features proportions. ALDEx2 transforms each proportional instance into log-ratios with Equation ~\ref{eq:CLR}.

This transformation normalizes the features of each sample to the geometric mean of each sample, and allows for comparisons of expression between and within RNA-Seq samples \cite{dillies2012}. The CLR-transformed data accounts for differences in sequencing depth between samples \cite{fernandes2013,lovell2011}. Much like how fluorescence in a qPCR reaction provides an internal standard to determine the quantity of amplified DNA, the geometric mean provides an internal standard to determine the abundance of a feature as a ratio to all other features in the sample. Taking the CLR of each feature ensures a one-to-one correspondance between features in the composition. This allows for feature changes to be observed relative to the geometric mean \cite{fernandes2014}. 

\section{Problem}
The assumption being made during the CLR transformation is that most features are either invariant or randomly varying. If there is systematic variation between groups simply due to presence absence of features, then this assumption is broken. (Demonstrate with intro figure) Figure ~\ref{Fig:intro_figs} demonstrates how this broken assumption can affect the data. Additionally, zeroes are problematic as they cannot be represented in logarithmic space. Therefore, prior to the log ratio transformation, zero count features are discarded if present in exclusive or conditions, or adjusted with an uninformative prior. 


In its current implementation, ALDEx2 removes features from samples if they have zero counts across all samples, and adjusts the remaining zero values with a prior of 0.5. The prior of 0.5 maximizes information in the data while minimizing its effect on the posterior\cite{fernandes2014}. In the language of propositional logic, the zero adjustment ALDEx2 utilizes is:

\begin{equation}
\begin{split}
	& \forall g[R(g) \land \neg AB(g)]\\
	\text{where}~
	\forall g &= \text{For all features} \\
	\text{R(g)} &= \text{remove feature g from all samples} \\
	\text{AB(g)} &= \text{feature g is present in samples of conditions A and B}\\
\end{split}
\label{eq:zero_removal_old}
\end{equation}

In ALDEx2, samples are considered to be in one of two conditions, for example Healthy vs. Disease or arbitrarily A vs. B. For the set of all features, if the feature is not in the samples of condition A and the feature is not present in the samples of condition B, then the feature is removed from all samples. The main problem of this current approach is that it is not well suited to compare sparse data as the prior adjustment becomes more influential on the geometric mean than the values of the features represented by non-zero values. Sparse data in the context of this paper can describe diverse datasets with many non-zero features in one condition, but numerous zero features in another.

Feature counts per sample are taken as the ratio over the geometric mean of the sample, therefore it is intuitive to use a denominator that is most representative of the sample. Figure \ref{Fig:GMEANS} illustrates how the inclusion of zero values can cause the geometric mean of a set of features to be skewed. 135 normally distributed random variates with a population mean of 20 and a standard deviation of 3 are plotted on both a histogram and a density plot. An additional 15 values of 0.5 are added to simulate zero count features that are adjusted with a prior of 0.5. Note how the inclusion of the 15 zeroes shifts the geometric mean denoted by the red arrow such that it no longer represents the majority of the features. By removing features with zero counts, the geometric mean represented by the blue arrow is able to encapsulate the center of the non-zero features. 



This paper proposes a solution where features are removed per condition if they are not present across samples within a condition. The rational behind this adjustment is that given prior metadata about a condition, there exist simulations where sequencing depth is sufficient to claim that zero counts are truly zeroes. For example, in an RNA-Seq experiment comparing the transcriptomes of a gene knockout organism and a wild type organism, there would be features expected to have zero counts in the gene knockout. It then becomes unintuitive to claim that features have a probability of being present with the prior adjustment of 0.5. This zero removal adjustment is an explicit claim that features are not present in the condition instead of claiming that they are potentially present. By reducing the effect of the prior associated with many zero features, this adjustment may grant more power to distinguish true differences between samples. Therefore, zero removal adjustment may provide a more stable internal standard when the geometric mean is used to center features for compositional data analysis.




\section{Methods}
Synthetic Data Set

There are various metrics that can be used to represent the nature of a set of data. For example, the arithmetic mean is simply the average of a set of numerical values.
For each sample, Monte-Carlo replicates of the set of features are drawn from the dirichlet distribution. Using the set of features, the variance of the

Across the set of features, the variance of each features is computed and

This is done by drawing Monte-Carlo instances of the 








ALDEx2 computes a per-sample geometric mean using the entire set of features, and this geometric mean

The metric that ALDEx2 uses currently is the geometric mean of centered-log ratio transformed data. (Add the figure with random variates here)


Given a set of features that are universal to all conditions, we are interested in finding the invariant set of features for geometric mean centering. 





However, if the variance across the set of variables is computed and the geometric mean is computed from only the variates that fall within the IQR of the variance, the resulting value is more representative of the actual values. 


















\section{Results}
Real Data Set


\section{Discussion}
Synthetic Unchanging Dataset

\section{Figures}
\begin{figure}[h]
\centering
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=.9\linewidth]{../figures/Fig_1a_EffectPlot.png}
\caption{}
\label{Fig:reads_500_effect}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=.9\linewidth]{../figures/Fig_1b_EffectHistogram.png}
\caption{}
\label{Fig:reads_500_histo}
\end{subfigure}
\caption{Caption for Fig 1 a\_b}
\label{Fig:intro_figs}
\end{figure}

\begin{figure}
\centering
\begin{subfigure}{.5\textwidth}
\centering
  \includegraphics[width=.9\linewidth]{../figures/histogram.png}
  \caption{}
  \label{Fig:GMEANS_A}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
\centering
  \includegraphics[width=.9\linewidth]{../figures/density.png}
  \caption{}
  \label{Fig:GMEANS_B}
\end{subfigure}
\caption{These plots represent 135 normally distributed random variates with a population mean of 20 with a standard deviation of 3. An additional 15 values of 0 were added and adjusted with a prior of 0.5 in order to simulate a dataset with 10\% of its values being sparse. Resulting geometric means are computed with and without zeroes. Red represents the geometric mean including the zeroes, blue represents the geometric mean without the zeroes. ~\ref{Fig:GMEANS_A} represents a histogram of the 150 variates. ~\ref{Fig:GMEANS_B} represents a density plot of the 150 variates.}
\label{Fig:GMEANS}
\end{figure}



\begin{figure}[h]
\centering
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=0.9\linewidth]{../figures/Fig_2a_IQR_Unadjusted.png}
\caption{}
\label{Fig:iqr_adjusted_effect_histo}
\end{subfigure}%
\begin{subfigure}{0.5\textwidth}
\centering
\includegraphics[width=0.9\linewidth]{../figures/Fig_2b_IQR_Adjusted.png}
\caption{}
\label{Fig:unadjusted_effect_histo}
\end{subfigure}
\caption{Caption for Fig 2 a\_b}
\label{Fig:method_figs}
\end{figure}


\begin{figure}[h]
\centering
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=0.9\linewidth]{../figures/Fig_3a_IQR_Unadjusted.png}
\caption{}
\label{Fig:reads_500_iqr_unadjusted_effect_histo}
\end{subfigure}%
\begin{subfigure}{0.5\textwidth}
\centering
\includegraphics[width=0.9\linewidth]{../figures/Fig_3b_IQR_Adjusted.png}
\caption{}
\label{Fig:reads_500_iqr_adjusted_effect_histo}
\end{subfigure}
\caption{Caption for Fig 3 a\_b}
\label{Fig:results_figs}
\end{figure}

\begin{figure}[h]
\centering
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=0.9\linewidth]{../figures/Fig_4a_IQR_Unadjusted.png}
\caption{}
\label{Fig:reads_iqr_unadjusted_effect_histo}
\end{subfigure}%
\begin{subfigure}{0.5\textwidth}
\centering
\includegraphics[width=0.9\linewidth]{../figures/Fig_4b_IQR_Adjusted.png}
\caption{}
\label{Fig:reads_iqr_adjusted_effect_histo}
\end{subfigure}
\caption{Caption for Fig 4 a\_b}
\label{Fig:discussion_figs}
\end{figure}


\clearpage

\printbibliography[title={References}]
\end{document}