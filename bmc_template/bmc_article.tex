%% BioMed_Central_Tex_Template_v1.06
%%                                      %
%  bmc_article.tex            ver: 1.06 %
%                                       %

%%IMPORTANT: do not delete the first line of this template
%%It must be present to enable the BMC Submission system to
%%recognise this template!!

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                     %%
%%  LaTeX template for BioMed Central  %%
%%     journal article submissions     %%
%%                                     %%
%%          <8 June 2012>              %%
%%                                     %%
%%                                     %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                                 %%
%% For instructions on how to fill out this Tex template           %%
%% document please refer to Readme.html and the instructions for   %%
%% authors page on the biomed central website                      %%
%% http://www.biomedcentral.com/info/authors/                      %%
%%                                                                 %%
%% Please do not use \input{...} to include other tex files.       %%
%% Submit your LaTeX manuscript as one .tex document.              %%
%%                                                                 %%
%% All additional figures and files should be attached             %%
%% separately and not embedded in the \TeX\ document itself.       %%
%%                                                                 %%
%% BioMed Central currently use the MikTex distribution of         %%
%% TeX for Windows) of TeX and LaTeX.  This is available from      %%
%% http://www.miktex.org                                           %%
%%                                                                 %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% additional documentclass options:
%  [doublespacing]
%  [linenumbers]   - put the line numbers on margins

%%% loading packages, author definitions

%\documentclass[twocolumn]{bmcart}% uncomment this for twocolumn layout and comment line below
\documentclass{bmcart}

%%% Load packages
\usepackage{amsthm,ams fonts,amsmath}
%\RequirePackage{natbib}
%\RequirePackage[authoryear]{natbib}% uncomment this for author-year bibliography
%\RequirePackage{hyperref}
\usepackage[utf8]{inputenc} %unicode support
%\usepackage[applemac]{inputenc} %applemac support if unicode package fails
%\usepackage[latin1]{inputenc} %UNIX support if unicode package fails


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                             %%
%%  If you wish to display your graphics for   %%
%%  your own use using includegraphic or       %%
%%  includegraphics, then comment out the      %%
%%  following two lines of code.               %%
%%  NB: These line *must* be included when     %%
%%  submitting to BMC.                         %%
%%  All figure files must be submitted as      %%
%%  separate graphics through the BMC          %%
%%  submission process, not included in the    %%
%%  submitted article.                         %%
%%                                             %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\def\includegraphic{}
\def\includegraphics{}



%%% Put your definitions there:
\startlocaldefs
\endlocaldefs


%%% Begin ...
\begin{document}

%%% Start of article front matter
\begin{frontmatter}

\begin{fmbox}
\dochead{Methodology}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Enter the title of your article here     %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{Finding the centre: correcting for compositional asymmetry in high-throughput sequencing datasets}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Enter the authors here                   %%
%%                                          %%
%% Specify information, if available,       %%
%% in the form:                             %%
%%   <key>={<id1>,<id2>}                    %%
%%   <key>=                                 %%
%% Comment or delete the keys which are     %%
%% not used. Repeat \author command as much %%
%% as required.                             %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\author[
   addressref={aff1},                   % id's of addresses, e.g. {aff1,aff2}
   email={jr2wu@uwaterloo.ca}   % email address
]{\inits{JR}\fnm{Jia r.} \snm{Wu}}
\author[
   addressref={aff2},                   % id's of addresses, e.g. {aff1,aff2}
   email={jean.macklaim@gmail.com}   % email address
]{\inits{JM}\fnm{Jean M.} \snm{Macklaim}}
\author[
   addressref={aff2},                   % id's of addresses, e.g. {aff1,aff2}
   email={bgenge3@gmail.com}   % email address
]{\inits{BL}\fnm{Briana L.} \snm{Genge}}
\author[
   addressref={aff2},
   corref={aff1},
   email={ggloor@uwo.ca}
]{\inits{GB}\fnm{Gregory B.} \snm{Gloor}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Enter the authors' addresses here        %%
%%                                          %%
%% Repeat \address commands as much as      %%
%% required.                                %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\address[id=aff1]{%                           % unique id
  \orgname{Department of Computer Science, U. Waterloo}, % university, etc
  \postcode{N2L 3G1}                                % post or zip code
  \city{Waterloo},                              % city
  \cny{Canada}                                    % country
}
\address[id=aff2]{%                           % unique id
  \orgname{Department of Biochemistry, U. Western Ontario}, % university, etc
  \postcode{N6A 5C1}                                % post or zip code
  \city{London},                              % city
  \cny{Canada}                                    % country
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Enter short notes here                   %%
%%                                          %%
%% Short notes will be after addresses      %%
%% on first page.                           %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{artnotes}
%\note{Sample of title note}     % note to the article
%\note[id=n1]{Equal contributor} % note, connected to author
\end{artnotes}

\end{fmbox}% comment this for two column layout

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% The Abstract begins here                 %%
%%                                          %%
%% Please refer to the Instructions for     %%
%% authors on http://www.biomedcentral.com  %%
%% and include the section headings         %%
%% accordingly for your article type.       %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{abstractbox}

\begin{abstract} % abstract
\parttitle{Background} %if any
High throughput sequencing  generates millions of reads of genomic data regarding a study of interest, and data from high throughput sequencing platforms can be modelled as count compositions. Subsequent analysis of such data yields information on transcription profiles, microbial diversity, or even relative cellular abundance in culture. Because of the high cost of acquisition, the data are usually sparse, and always contain far fewer observations than features. However, an under-appreciated pathology of these data are their often unbalanced nature: i.e, there is often systematic variation between groups simply due to presence or absence of features, and this variation is important to the biological interpretation of the data. A simple example would be comparing transcriptomes of yeast cells with and without a gene knockout. This causes samples in the comparison groups to exhibit varying centres contributing to false positive and false negative identifications. 

\parttitle{Results} %if any
We extend a previously described log-ratio transformation method used for the comparison of differential relative abundance between two groups in a Bayesian compositional context. We demonstrate the pathology in  modelled and real unbalanced experimental designs to show how this  causes both false negative and false positive inference. We then introduce several approaches to demonstrate how the pathologies can be recognized and addressed. The transformations are implemented as an extension to a general compositional data analysis tool known as ALDEx2 which is available on Bioconductor. 

\parttitle{Conclusions}The IQLR and the LVHA methods are relatively robust, and should be used when the basic log-ratio approach exhibits asymmetry. We recommend the LVHA transformation for asymmetric transcriptome datasets, and the IQLR method for all other datasets.

\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% The keywords begin here                  %%
%%                                          %%
%% Put each keyword in separate \kwd{}.     %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{keyword}
\kwd{transcriptome}
\kwd{Bayesian estimation}
\kwd{count composition}
\kwd{sparse data}
\end{keyword}

% MSC classifications codes, if any
%\begin{keyword}[class=AMS]
%\kwd[Primary ]{}
%\kwd{}
%\kwd[; secondary ]{}
%\end{keyword}

\end{abstractbox}
%
%\end{fmbox}% uncomment this for twcolumn layout

\end{frontmatter}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% The Main Body begins here                %%
%%                                          %%
%% Please refer to the instructions for     %%
%% authors on:                              %%
%% http://www.biomedcentral.com/info/authors%%
%% and include the section headings         %%
%% accordingly for your article type.       %%
%%                                          %%
%% See the Results and Discussion section   %%
%% for details on how to create sub-sections%%
%%                                          %%
%% use \cite{...} to cite references        %%
%%  \cite{koon} and                         %%
%%  \cite{oreg,khar,zvai,xjon,schn,pond}    %%
%%  \nocite{smith,marg,hunn,advi,koha,mouse}%%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%% start of article main body
% <put your article body there>

%%%%%%%%%%%%%%%%
%% Background %%
%%

\section*{Background}
High throughput sequencing (HTS) technology is used to generate information regarding the relative abundance of features.  In these designs, DNA or RNA is isolated, a library is made from a  sample of the nucleic acid, and a random sample of the library is sequenced on an instrument. The output is a set of short sequence tags, called reads, which are mapped to example sequences for each feature to generate a table of read counts per feature for every sample. Traditionally, samples comprise a set of features whose identity depends on the experimental design. For example, features are genes in the case of RNA-seq or  metagenomic sequencing, or are operational taxonomic units (OTUs) when the objective is identifying microbial diversity. 
 
The instruments used for HTS have an upper limit on the total number of reads delivered; for example the same library sequenced on an Illumina MiSeq or an Illumina NextSeq will deliver approximately 20 million or 400 million reads. HTS instruments thus deliver a fixed-sum random sample of the sequences that are in the library, which itself is a random sample of what was in the environment. 

Data from HTS instruments are usually analyzed by count based methods which use a negative binomial or zero-inflated Gaussian model, and assume the features are independent and identically distributed for statistical tests, and that the majority of features are invariant \cite{Auer:2010aa,Anders:2013aa}. In addition, the variance in HTS data is usually larger than the mean (overdispersed), and negative binomial and similar models are generally adequate when the underlying assumptions are approximated.

Many HTS datasets do not fit the usual statistical models. For example, in meta-transcriptomic datasets the relative abundance of both the organism and of the genes expressed by the organism can both change independently, or in meta-genomic datasets there is no logical reason for feature to follow any particular statistical model. The assumption that the majority of features are invariant is broken if there is any sort of systematic variation between groups. For example, when comparing microbial diversity between sampling sites or conditions, organisms present in one sub-site or condition may be absent from another \cite{Macklaim:2015aa,Hummelen:2010,Gajer:2012}. In the case of multi-organism RNA-seq (meta-transcriptomics), organisms resident in one condition may have a different expression profile and abundance than those resident in a second condition \cite{macklaim:2013}. In the case of a single-organism RNA-seq, samples from one condition may contain more genes than samples from another condition \cite{Lang:2015aa,Peng:2014aa,Zhao:2013aa,Gierlinski:2015aa}. These differences are represented by either zeroes or low count features that occur systematically in only one group. Meta-transcriptomic datasets are thus some of the most difficult experiments to analyze \cite{macklaim:2013,fernandes:2013} since the datasets do not fit multiple assumptions of existing tools. We have shown previously that existing count-based tools fail to give sensible answers in meta-transcriptome and other datasets that exhibit asymmetry  \cite{fernandes:2013, fernandes:2014,gloorAJS:2016}. 

\subsection*{A ratio based approach to analyzing HTS:}
Another approach to analyze data taking into account the fixed capacity of the instrument and the random sampling of the library (and the environment) is to model the data as a multivariate probability distribution and to examine the result with the principles of compositional data analysis \cite{Aitchison:1986,fernandes:2013}. This method is instantiated in the ALDEx2 Bioconductor package. Conceptually, the approach is similar to sequencing many different technical replicates of the underlying biological replicates, treating the resulting data as ratios of the features and reporting the mean value of the technical replicates. This approach has been found to be a generally useful tool that works for meta-transcriptomic datasets \cite{macklaim:2013} and translates to many different experimental designs \cite{fernandes:2014, mcmurrough:2014,gloorFrontiers:2017,Macklaim:2018aa,Almeida:2019aa}. 

The basis for the approach used by ALDEx2 is the centred log-ratio (CLR) transformation proposed by Aitchison \cite{Aitchison:1986} and defined below. However, this approach requires that the denominator used to calculate the CLR be comparable across all samples.  The ratio-based approach is  similar to relative quantitative PCR (qPCR), a method in common use in molecular biology that measures relative abundance of molecules in a mixture \cite{Thellin:1999aa,Vandesompele:2002aa} and is often used as the gold-standard to validate HTS results. In this type of qPCR the feature of unknown abundance is determined relative to the abundance of a feature of (presumed) known abundance. This standard can be a housekeeping gene or can be a DNA molecule of known amount added to the mixture. It is well known that the relative abundance measure will change when a different species is used as the denominator, leading to the use of multiple (presumed invariant) species in some cases. Thus, one shortfall of any ratio-based approach, is to determine the appropriate denominator. 

The potential for a change in cell number and the potential for expression linkage of genes in biological systems, coupled with the inability to collect a large enough number of sequence reads, can lead to experiments with an apparent or a real asymmetry in relative abundance of many genes or features. Such an asymmetry will result in mis-centering of the data when conducting differential abundance analyses, largely, but not exclusively because of the effect on the geometric mean upon which the CLR depends. The asymmetry will also affect the scale-invariance of the data, since a value of 0 is not scaled when multiplied by a constant. Note, that it is also entirely possible for the dataset \emph{as a whole} to be centred, but for the particular comparison of interest to not be centred. This could arise because of a systematic experimental bias that is unknown to the investigator. 



For convenience, the analyses and discussion here are drawn from RNA-seq, or transcriptome, experiments where the data are exploring the relative abundance of features that are gene transcripts found in cells in an environment. However, the examples, results and conclusions apply without restriction to metagenomic sequencing, microbial diversity sampling (by 16S rRNA gene sequencing) or to \textit{in-vitro} selection experiments \cite{fernandes:2014,mcmurrough:2014,gloorFrontiers:2017}. 

\subsection*{Choosing the denominator:}

The basic principle of compositional data analysis as developed by Aitchison is to convert the data into log-ratios between the features for each sample \cite{Aitchison:1986}. Formally, Aitchison defined a composition as a vector \textit{\textbf{x}}  of positive values \textit{x\textsubscript{1}}\ldots\textit{x\textsubscript{D}} whose features  sum to an arbitrary constrained constant $\alpha$. Absolute values of features in a composition are uninformative, and so the only information available in compositional data are the relative magnitudes, or the ratios between the pairs of components. For example, the only knowledge available is that the gene 1:gene 2 ratio is 5, but the absolute abundance of either is unavailable. This is the case in HTS since the count observed for a feature contains no information regarding the absolute number of molecules in either the sequencing library or the environment, although the magnitude of the count contains information on the precision of the estimate.

Data collected from high throughput sequencing are count compositions \cite{fernandes:2014,gloorAJS:2016}. Count-based tools do not address the compositional nature of HTS data \cite{gloorAJS:2016,fernandes:2014} and assume that the features are sufficiently independent when there are enough of them, or when they fulfill certain statistical properties \cite{Weiss:2016aa}. Much effort is placed on `normalizing' the data to have a consistent read depth instead of treating the data as compositional \cite{Sun:2013aa,McMurdie:2014a}.

However, since all read count totals from a machine are arbitrary we should treat the data as an equivalence class  where the composition contained in vector \textit{\bf{x}} can be scaled into an identical composition \textit{\textbf{y}} by multiplication of a constant $\alpha$ \cite{barcelo:2001}. Thus, in the ideal case, we can discuss any composition as being a probability vector scaled by $\alpha$ without loss of precision \cite{fernandes:2013}. 

One way of satisfying the need to examine the ratios between features is to use the centred-log-ratio (CLR) transformation proposed by Aitchison, defined as: 

\begin{equation}
\textbf{x}_{clr} = log  \big( \frac{x_i}{G(\textbf{x})}   \big)_{i=1\dots D}
\label{eq:CLR}
\end{equation}

where $G(\textbf{x}) =$ the geometric mean of the D features of $\textbf{x}$.

%\text{where}~
%	\textbf{x}_{clr} &= \text{A composition transformed by CLR} \\
%	x_i &= \text{A feature of the non-transformed composition (\textbf{x})} \\
%	D &= \text{The number of features of \textbf{x}} \\ 
%	}

The CLR, and any other ratio-based method is, at least in theory, scale-invariant because if the parts of \textit{\textbf{x}} are counts with $\alpha=$\textit{N} reads, then: 

\begin{equation}
	\textbf{x}_{i,clr}= log\big( \frac{Nx_i}{G(N\textbf{x})}   \big) =  log\big( \frac{x_i}{G(\textbf{x})}  \big).
\label{eq:equip}
\end{equation}
The  important caveat that limits this ideal situation when dealing with high throughput sequencing data is that the total read count, $\alpha$, for each sample should be similar. The CLR is the default denominator used by ALDEx2, and see below for how ALDEx2 handles the problem of varying read depth.

Aitchison \cite{Aitchison:1986} also defined the ALR, the additive log-ratio as: 

\begin{equation}
\textbf{x}_{alr} = log  \big( \frac{x_i}{x_D}   \big)_{i=1\dots D-1}
\label{eq:ALR}
\end{equation}
where, following from above, $\textit{\textbf{x}}_{alr}$ is the composition transformed by ALR, and the denominator is the $D^{th}$ feature of \textit{\textbf{x}}, which by convention is the feature chosen to be constant.  

In the ALR, the log-ratio is thus determined by selecting one presumed invariant feature as the denominator. The ALR is thus similar to the relative qPCR approach in common use in molecular biology. The ALR and CLR can be viewed as the two limits of a continuum of incomplete knowledge about the proper internal standard, or basis, by which relative abundance should be judged. The ALR uses one presumed constant feature as the basis; while the CLR  presumes that the majority of features are not changed, leading to the use of the geometric mean of all features as the basis. We can however, choose to use combinations of other features as the basis.

\subsection*{HTS data are sparse.}It is common for HTS data to be sparse, that is, for a given sample to contain features with counts of 0. One limitation of the log-ratio approach is that ratios have no meaning if the denominator contains a 0 value. The sparsity of a sample is affected by the total number of reads obtained for each sample, and each sample in a transcriptome contains between thousands and tens of thousands of features each of which may have a potential dynamic range of over 4 orders of magnitude. In many cases a transcriptome dataset will be composed of several groups, where the expression of a feature (gene) is so low that it is below the detection limit in one group, and very high in another group. The expression of genes in biological systems is linked, and some genes control the expression of other genes, either by increasing or decreasing their relative abundance. Furthermore, the cell has a built-in control system whereby gene expression itself appears to be a composition, that is, the expression levels of all genes in a cell in a given environment are constrained by an absolute upper bound  \cite{Scott:2010}. In eukaryotes, the upper bound can be changed with surprisingly small genetic changes \cite{Loven:2012aa}. In the case of a meta-transcriptome a population of cells will does not necessarily exhibit total gene expression with an upper bound, since the cells themselves can change in both absolute and relative abundance in a mixture. 

The assumption being made when using the CLR transformation to identify features that differ between groups is that most features are either invariant or vary at random when comparing the two groups. However, marked asymmetry can break this assumption.

%% Figure 1 about here

Throughout, we use two plots to summarize the location of the features in multivariate datasets. The Bland-Altman (BA) plot  \cite{altman:1983} plots the mean log-ratio abundance on the x-axis and the difference between groups on the y-axis. The BA plot is efficient at showing the relationship between (relative, mean log-ratio) abundance and difference, but contains little information on the per-feature dispersion in the data. The Effect size plot \cite{gloor:effect} complements the BA plot by showing the relationship between a measure of dispersion (on the x-axis) and the difference between groups (on the y-axis). All plots are in log units calculated a base of 2. The ratio between these two values is a proxy for the effect size statistic calculated by ALDEx2. Difference and dispersion are calculated using methods that are indifferent to distributional assumptions and are defined in the Implementation section. Figure \ref{Fig:f1a} shows that incorrect estimates of the location of the data can be achieved with seemingly minor variation within simulated data. The goal is to identify a basis that best represents each sample so features can be accurately compared even when the data contains an asymmetry.



\section*{Results and Discussion}

\subsection*{Simulated Data}


RNA-Seq data was simulated for benchmarking purposes. Assemblies from \textit{Saccharomyces cerevisiae} uid 128 and  a complete reference genome of \textit{S. cerevisiae} were drawn from GenBank. The R package \texttt{polyester v1.10.0} \cite{polyester:2016} was used to simulate an RNA-Seq experiment with 2 groups of 10 replicates with 20x average sequencing coverage across the simulation experiment. For the base dataset, forty genes were chosen at random to have 2-5 fold expression difference, and these were apportioned equally between the two groups. These 40 features serve as an internal control of true positives for each dataset as their fold changes are explicit and should always be displayed as differentially expressed. We used bowtie2 \cite{bowtie2} to align the simulated reads  to the \textit{S. cerevisiae} reference genome. Labeling each group as A and B is arbitrary and hence the first 10 samples belong to condition A, and the final 10 sample belong to condition B. There are a total of 6349 features in these simulated data, but only the first 1000 genes by order were chosen for the majority of the figures. 

An additional 51 datasets derived from the base dataset are generated in order to benchmark how well the *LR transformations centre the data in the resultant set of datasets with sparsity ranging from 0\% to 51\% sparse in one condition relative to the other. 

%% Figure 2 about here

\subsection*{Four alternative methods}


In its initial implementation, ALDEx2 computes the CLR, a per-sample geometric mean using all features as the baseline for feature comparisons. The `Symmetric dataset' panel in Figure \ref{Fig:f1a} is an effect plot demonstrating that the 40 internal control features are found to be both statistically significant and to have an effect size greater than 1 between the two groups, and the remainder of the features have very small difference, and correspondingly have an effect size much less than 1; that is, the results are as expected. 

The inset histogram shows that the distribution of difference values between groups A and B is symmetric and has a location of 0. However, the introduction of small amounts of asymmetry strongly affect the results. The asymmetric 2\% dataset is the base dataset modified by setting the count value to 0 for 20 features chosen at random from Group A, and likewise the asymmetric 6\% dataset has 60 features from group A set to 0. It is apparent from the two right panels of Figure \ref{Fig:f1a} that this low level of simulated asymmetry breaks the assumption that most features are invariant, and the location of the difference between groups is no longer at the origin.  The small amount of asymmetry is shifting the geometric mean of the data such that the two groups are calculated using different denominators, causing bias. Thus, if even a small subset of features in a sample systematically do not follow the central tendency of the data, the geometric mean can be unreliable as a baseline. It is unlikely that the problem will be as easy to diagnose in real data as in simulated data. 

As can be seen in Equation \ref{eq:CLR}, the major determinant of the centre of a sample is the denominator, or basis, used to compute the CLR. Thus, one obvious approach to address the problem is to compute the geometric mean of a subset of features that are more representative of the central tendency of the data, and to use this value as the denominator in the equation. We  examined four different approaches to identifying the features to include in the denominator. 

 
 
The transformation in Equation \ref{eq:iqlr} is termed the IQLR transformation. The results of this method are shown in Figure \ref{Fig:f2a}:IQLR on the Asymmetric 2\% dataset. The IQLR transformation restores the centre of the dataset to the origin, and the proper set of features is identified as being both significant, and having an effect size greater than 1.


The second approach uses as the denominator the set of non-zero features in each group.  Thus, in this case the geometric mean of group A and group B are based on different, but potentially overlapping, sets of features, this approach is called the no-zero log ratio (NZLR). As shown in Figure \ref{Fig:f2a}:non-zero, the NZLR method also restores the centre of the data to the origin and identifies the proper set of features as differential in the simulated dataset. 

%% Figure 3 about here

%% Figure 4 about here

%The  third  approach uses as the denominator a set of user-defined features, and is termed the ULR for user-defined log-ratio. Thus, the user could choose to use one feature, in which case the approach would be the same as the ALR, or all features, in which case the result would be the same as the CLR, or a subset chosen based upon prior information. In the case of RNA-seq, this could include the set of genes involved in translation as these have been shown to be relatively stable across multiple conditions \cite{Scott:2010}, and can be presumed to represent a set of genes that are representative of the overall growth state of the cell. In principle, any set of features could be used although the investigator would need to present evidence for the  appropriateness of those features chosen in any particular experiment. Since it is trivial to identify unchanging features in a test dataset, the effect of this approach is not illustrated but also resulted in the location of the data being returned to 0. 

The third approach was to identify the intersect between groups of those features that have variance which is in the bottom quartile across and a relative abundance in the top quartile in each group. This is referred to as the low variance high abundance Log Ratio feature \textit{LVHA} set. In essence, the VALR set of features is an attempt to identify those features that would be similar to the ideal user-defined set; being relatively abundant with low variance in all groups in the dataset.  
 
The transformation in Equation \ref{eq:vale} is termed the LVHA transformation (low variance high abundance log-ratio). The results of this method are shown in Figure \ref{Fig:f2a}:LVHA on the Asymmetric 2\% dataset, and has similar properties to the IQLR on this dataset. 

The fourth approach replaces the geometric mean in Equation \ref{eq:CLR} with the  median of the vector since this should be a robust estimate of the midpoint of the data. 

\subsection*{Limitations of the approaches}

We  explored the limitations of these approaches in two ways. First, we examined how asymmetric  sparsity  affected the ability of the approaches to properly centre the data. Figure \ref{Fig:failure} shows that the centre of the CLR-transformed data deviates from 0 when the data have even very small amounts of asymmetric sparsity. The deviation is much smaller when the median is used as the denominator, but is not, in general, the best solution and the median is not recommended, nor included in the production version of ALDEx2. The IQLR, LVHA and NZLR approaches are able to properly centre the data when even large amounts of asymmetric sparsity are present. The breakdown point for the LVHA methods is 24\% sparsity in this dataset, and is approximately  45\% sparsity for the  IQLR and NZLR. All are obviously better choices than the CLR, or the median when asymmetric sparsity is present. Of note, the LVHA approach will fail if no appropriate denominator can be found and this is the reason that the LVHA correction ends at 24\% in this figure. 

In a biological context it is entirely reasonable that asymmetry could occur because of an asymmetry in counts  rather than sparsity. For example, the default gene expression condition for many genes is low-level expression, and the inclusion of a transcriptional activator could increase expression of many genes from very low expression to very high expression. In the context of 16S rRNA gene sequencing study, it is possible for samples to be dominated by one very abundant organism but to contain many other taxa at low abundance. Thus, we would have a count asymmetry that is not necessarily based on sparsity. Furthermore, sparsity is strongly affected by read depth, the same samples derived from a sequencing dataset from an Illumina NextSeq run delivering a total count of 400M reads will be substantially less sparse than those derived from an Illumina MiSeq run delivering a total count of 25M reads, however any underlying asymmetry will be preserved.

Thus, rather than modelling sparsity, we modelled low-count asymmetry by changing the asymmetry to a defined count of 1; any asymmetric count will behave similarly. The results, shown in Figure \ref{Fig:ones} show that an asymmetry where the asymmetric value is 1 again results in the location of the data being displaced from 0. However, when the IQLR and LVHA methods are used the location of the data is restored to 0. Not surprisingly, the NZLR does not restore the data to the proper location since the asymmetry is not driven by sparsity. The median and user-defined methods were not tested. We suggest that the NZLR method be used only when the other approaches fail, and when the investigator is confident that sparsity is driving the asymmetry in the data. 

%% Figure 5 about here

\subsection*{Example of a meta-RNA-seq dataset}
 We finally introduce the example of an real meta-transcriptome dataset collected to determine the differences in gene expression of the vaginal microbial community in the healthy (H) and bacterial vaginosis (BV) states. The vaginal community can be dominated either by a few members of the \textit{Lactobacillus} genus in the H state, or by a mixed group of anaerobic bacterial genera in the BV state \cite{Ravel:2010}. In either state the members of the bacterial consortium from the other state are either very rare or absent. The data presented in Figure \ref{Fig:bv} show the distribution of between group difference, dispersion and relative abundance using a Effect size plots \cite{gloor:effect}. There are 10 H samples and 12 BV samples; the count table was generated using the methods in \cite{Macklaim:2018aa}, from data deposited at the European Nucleotide Archive PRJEB31833. The table of counts is freely available in the  supplementary information. 
 
The values in Figure \ref{Fig:bv}:denom=all were computed using the CLR. Each point represents the intersect of the two given summary statistics (Difference is the diff.btw, Dispersion is the diff.win) taken from the ALDEx2 output for an individual protein or enzymatic function in the dataset \cite{macklaim:2013}.  We can see that there is a large asymmetry in distribution, the most striking of which are the functions in BV located below the midline on the y-axis; there are a large number of features centred at about 2,-5. This asymmetry is driven by the greater complexity of the BV microbial community, and the generally larger and more complex genomes in the set of bacteria found in BV \cite{macklaim:2013}. The asymmetry is composed of both presence-absence (sparsity) and large differences between groups. This can be seen with the sparsity overlay color, where functions that contain one or more zeros are coloured in a darker brown. 

Note that there appears to be two clusters of functions that are just above the y-axis midline. The ones at 4,2 are composed of sparse functions expressed at moderate levels in BV but that are absent or very rare in H.  We also see a second group composed of functions found in common between the the H and BV group that is  expressed at very high relative levels, centred around 1,2 on the  plot. These are generally housekeeping functions that are central and required by all living organisms, and we can see that the two sets of housekeeping functions that are  highlighted cluster here: ribosomal protein functions in blue, and glycolytic functions in magenta. Many of the functions in these groups are often used as internal standards for comparison by qPCR as it is assumed that their expression is invariant \cite{Scott:2010}. The median offset of the two sets of housekeeping functions  on the y-axis is given, and we can see that they are both observed to be substantially above the expected location of 0 when the CLR is used to determine differential relative abundance.   

%% Figure 6 about here

The other three panels in Figure \ref{Fig:bv} shows the result of applying  three adjustment approaches to the asymmetric meta-RNA-sea dataset. The IQLR, LVHA and user-defined-adjustment methods centred the data  better than did the CLR. In this case we used the set of ribosomal protein functions in blue as the denominator in the denom=ribosome panel. We can see that the bulk of the expected invariant groups are closer to the y-axis midline with all three adjustments, and the offset of the ribosomal and glycolytic functions is reduced by half or more when compared to the CLR result. The LVHA adjustment brings the housekeeping functions very close to the centre of the dataset.  Centring on the geometric mean of the low variance but high (relative) abundance functions provides a substantial improvement over all other methods. Here both the very rare and assumed invariant functions are near the y-axis centre line and the points representing the ribosomal and glycolytic functions are nearly perfectly centred.

\section*{Conclusions}


Biological data derived from high-throughput sequencing is rarely ideal and exhibits many pathologies. It is currently difficult to examine complex communities using RNA-seq because of a mismatch between the assumptions of the tools and the characteristics of the data. Asymmetries also often exist in metagenomic, and in vitro selection (SELEX) datasets. In particular, such data can be derived from asymmetric environments, where sets of genes, operational taxonomic units, or organisms can be present or abundant in one condition and absent or rare in another. Alternatively, an asymmetry in the data can arise because of a systematic failure in experimental design, for example, through improper blocking or the presence of outlier samples. In any of these instances the presence of an asymmetry may not be obvious. 

We demonstrated that even a small number of asymmetric features can change the location of the dataset, leading to both false positive and false negative differences being identified. We showed that the asymmetry can be associated with sparsity or by differences near the margin; in either case, the pathology was similar. We tested  different methods to properly centre the data, and found that the IQLR and LVHA-specified centring approaches were the most general purpose and thus recommended for use. All are implemented in the ALDEx2 R package and can be used in conjunction with the propr package for compositional association \cite{Quinn:2017}. 

When the asymmetry is moderate, the IQLR correction is most appropriate. This correction makes the assumption that those features with variance between the first and third quartile of variance, are a suitable proxy for the expected `typical' variance of the data. This approach can tolerate up to 25\% asymmetry in the data when the geometric mean of these features are used as the denominator for a log-ratio normalization. In fact, we recommend that the IQLR be used as the default when performing differential relative abundance analysis, since this normalization makes no strong assumption about the data and appears to never perform worse than the CLR normalization until failure of the approach occurs. In this case ALDEx2 will report an error.

More extreme asymmetry, as found in our vaginal transcriptome dataset, forces the investigator to make strong assumptions about the underlying data and use the LVHA correction. The assumptions made here are similar to the assumptions made when performing qPCR: that there are one or more invariant features in the data, and that these will typically be relatively abundant house-keeping functions. We found that these features could be identified as having low variance but high relative abundance and can be used as exemplars of `invariant' features. This assumption is similar to the one that would be made by qPCR which is the standard approach used to validate HTS data. We observe that not all datasets have feature sets that are compatible with the LVHA approach, in these cases the investigator can make an even stronger assumption and choose one or more features that prior knowledge suggests would be appropriate. 

In any case, it must be remembered that the results of any analysis must be interpreted as \emph{abundance relative to the chosen invariant part of the dataset}, and not as changes in absolute abundance.

\section{Availability and requirements}

The methods are included in the ALDEx2 R package available at Bioconductor (https://www.bioconductor.org/packages/release/bioc/html/ALDEx2.html). All data, and scripts used for the manuscript, are publicly available at the GitHub repository (https://github.com/JRWu/Log-Ratio-Publication). The raw data for Figure 5 has been deposited in the European Nucleotide Archive (PRJEB31833) and will be publicly available when the manuscript is accepted. 

\section{Competing interests}

None of the authors declare competing interests.

\section*{Methods}


It is worth recalling that essentially all HTS data come from underpowered experimental designs, in the sense that there are more features than there are samples: indeed it is common, because of cost to conduct and analyze only pilot-scale experiments. Thus, the strength of evidence for statistical inference must be weak, but paradoxically, the features that are identified as differentially abundant must appear to be much more different between groups than the actual data support  \cite{Halsey:2015aa}. These can only be validated by replication or meta-analysis \cite{Cumming:2008aa}, both of which are rare in both the transcriptome and microbiome fields. 

We will adhere to the following notation below:
\begin{itemize}
\item{indices} will be denoted as lower case, italic; i.e., \textit{i,j,k,n}. 
\item{a vector} will be denoted in bold, lower case, italic; i.e., The notation \textit{\textbf{s$_{ij}$}} will denote the $j^{th}$ feature in the the $i^{th}$ sample vector. Vectors contain $D$ features. 
\item{a matrix or array} will be denoted in upper case, roman text; i.e, S
\end{itemize}


When estimating differential relative abundance it is important to properly estimate the dispersion, $\tau$, of the $j^{th}$ feature in all samples; dispersion can be represented by the following simple model:

\begin{equation}
    \tau_{j} = \nu_j + \epsilon_j
\label{eq:dispersion}
\end{equation} 
where $\nu$ represents the underlying biological variation and $\epsilon$ represents the stochastic error  from all the steps involved in the collection, preparation, and sequencing of the dataset. The majority of extant analysis tools utilize point estimates of both parameters and generally assume that  $\epsilon$ is small relative to $\nu$.  The basis of negative-binomial based tools is that there is some underlying similarity in the distribution of $\nu$ and $\epsilon$  for all features in all samples at a given relative abundance level. That is, if the $j$ features were ordered by abundance, that the expected value of $\nu_j$ would be  $\sim \sum (\nu_{j-m}\ldots \nu_{j+m}) / 2m $ where \textit{m} is some small offset in the abundance index. Similar logic applies to estimating the expected value of $\epsilon$, but many tools offer  more complex additional models to estimate these parameters for troublesome data. Supplementary Figure 1 shows plots of variance vs. abundance for four different types of experimental designs, and only the idealized transcriptome dataset is a reasonable fit to the model. 

We  observed that $\epsilon$ can be substantially larger than $\nu$ at the low count margin \cite{fernandes:2013,gloorAJS:2016}, and that properly accounting for this realization alone can result in an excellent fit to even problematic data. 
The ALDEx2 R package  uses Bayesian modelling to generate a probability function for  $\epsilon_{ij}$ that can be used to place bounds on the uncertainty of the the observed data \cite{fernandes:2013,gloorAJS:2016}. If there are two groups, A and B,  this requires that the data comparison is properly centred on the difference between these groups; that is that the denominator used in the two groups is comparable.  

%This approach is implemented in the ALDEx2 Bioconductor package and substantially reduces the false positive identification rate in microbiome and transcriptome data while maintaining an acceptable true positive identification rate \cite{fernandes:2013,Thorsen:2016aa}Thus, a reliable analysis can be obtained by incorporating an `in silico' technical replication function which explicitly models the variation in $\epsilon$ as a probability density function on a per feature, per sample basis.



The starting point for analysis is matrix S, containing \textit{n} samples $ \times~D$ features. A  sample vector contains the number of reads mapped to any of the $j$  features in the $i^{th}$ sample,  $\textbf{s}_i=[j_1,j_2 \ldots j_D]$, where $i=1 \ldots n , j=1 \ldots D$. As noted above, since the total number of counts is determined by the machine, these data are compositional and are an example of an equivalence class with $\alpha_{i} = \sum \textbf{s}_{i}$ \cite{Gloor:2016cjm,gloor2016s}. 

In theory, the vector $\boldsymbol{s}_i$ can be adjusted to a unit probability vector,  ${\boldsymbol{p}_i=[p_1,p_2 \ldots p_D] }$, i.e. $\alpha=1$, without loss of information by the maximum likelihood (ML) estimate  $\boldsymbol{p}_i=\boldsymbol{s}_i / \alpha_{i}$. In this representation, the value of the $j^{th}$ feature in the $i^{th}$ sample is a ML estimate of the probability of observing the counts conditioned on the fractional  $f$ that the feature represents in the underlying data and on the total read depth for the sample; i.e., $\mathbb{P}_{i,j}(f_{i,j}|\alpha_{i})$. However, the maximum likelihood estimate will be exponentially inaccurate when the dataset contains many values near or at the low count margin \cite{Newey:1994} as is common in sparse HTS data. Instead ALDEx2 uses a standard Bayesian approach \cite{Jaynes:2003} to infer a posterior distribution of the unit vector directly from $\boldsymbol{s}_i$, by drawing $k$ random Monte-Carlo instances from the Dirichlet distribution with a uniform, uninformative prior of 0.5, i.e.:

\begin{equation}
\textrm{P}_{i (1 \ldots k)}=
\begin{pmatrix}
    \boldsymbol{p}_1 \\
    \boldsymbol{p}_2 \\
    \vdots \\
    \boldsymbol{p}_k \\
\end{pmatrix} =
\begin{pmatrix}
    p_{i,11} & p_{i,21} & p_{i,31} & \dots  &  p_{i,D1}  \\
    p_{i,12} & p_{i,22} & p_{i,32} & \dots  &  p_{i,D2}  \\
    \vdots & \vdots & \vdots & \ddots &  \vdots  \\
    p_{i,1k} & p_{i,2k} & p_{i,3k} & \dots  & p_{i,Dk} \\
\end{pmatrix}
\sim Dirichlet_{(1 \ldots k)}( \boldsymbol{s}_i + 0.5)
\label{eq:matrix}
\end{equation}


This approach has consistent sampling properties and removes the problem of taking a logarithm of 0 when calculating the log-ratio because the count 0 values are replaced by positive non-zero values that are consistent with the observed count data \cite{fernandes:2013,gloorAJS:2016}. Each of the Monte-Carlo instances, by definition, conserves proportionality and accounts for the fact that there is more information when $\alpha_i$ is large than when it is small. This partially restores scale invariance to the data by providing a distribution of values where the uncertainty of  features scales inversely with the read depth \cite{fernandes:2013,gloorAJS:2016}. Sampling from the Dir distribution in combination with the log-ratio transformation removes the need to perform a count normalization step. 

In the original implementation of ALDEx2 each of the Monte-Carlo Dirichlet instances was CLR-transformed row-wise using Equation \ref{eq:CLR} and the entire dataset was stored in the array $\textrm{C}$ with dimension ${n,D,k}$. 
Since the purpose of this work is to test alternative log-ratio transformations, these will be referred to generically as *LR from this point forward. Note that the *LR  is scale invariant since the same output vector is obtained for all members of the equivalence class. For convenience a logarithm of 2 is used for any of the *LR transformations so that differences can be expressed in a intuitive scale.  


Summary statistics from the distribution of *LR values for each feature can be calculated and reported as either expected values or as medians of the distributions \cite{fernandes:2013}. If we have two groups, A and B, where the indices of the samples in the first group are $1 \ldots i_a$ and the indices of the samples in the second group are $i_{a + 1} \ldots n$, then the distributions of *LR values for the $j^{th}$ feature of the two groups can be contained in the vectors: $\textit{\textbf{a}}_j = \mathrm{C}_{(1 \ldots i_a)j(1...k)}$ and, $\textit{\textbf{b}}_j = \mathrm{C}_{(i_{a + 1} \ldots n)j(1...k)}$. Summary statistics use for plotting and analysis are: 

%  the features are computed from a vector $X_j$ constructed to contain the $k$ CLR transformed instances for the $j^{th}$ feature across all samples $S_{1\ldots n}$; if we have two groups, A and B, it is constructed as the union of two sub-vectors  $X_j = A_{(1 \ldots n)j(1...k)} + B_{(1 \ldots n) j(1\ldots k)}$ where, $A_{j(1...k)} = [x_{j,A1}, x_{j,A2} \dots x_{j,Ak}]$ and $B_{j(1...k)} = [x_{j,B1}, x_{j,B2} \dots x_{j,Bn}]: k=m+n$. The length of $X_j$ is the product of the number of samples and $k$. We can calculate and plot several summary statistics from  ALDEx2.
 
\begin{itemize}
\item{Log-ratio abundance} of a feature is the median of the joint distribution of *LR values from  groups A and B; i.e., it is the median of $ \textit{\textbf{a}}_j \cup \textit{\textbf{b}}_j$. 

\item{Dispersion} is the median of the vector $\Delta_{\textit{\textbf{a}}_j\lor \textit{\textbf{b}}_j}  = maximum(|\textit{\textbf{a}}_{j} - \textit{\textbf{a}}_{\langle j \rangle}|~,~|\textit{\textbf{b}}_{j} -\textit{\textbf{b}}_{\langle j \rangle}| )$, where $\langle \rangle$ indicates a random permutation of the vector. The reported dispersion for each feature is denoted as $\tilde{\Delta}_{\textit{\textbf{a}}_j\lor \textit{\textbf{b}}_j}$ and is a conservative surrogate for the median absolute deviation when $\textit{\textbf{a}}_j$ and $\textit{\textbf{b}}_j$ contain many entries \cite{fernandes:2013}. 

\item{Difference} between groups is the median of the vector $\Delta_{\textit{\textbf{a}}_j-\textit{\textbf{b}}_j}  = (\textit{\textbf{a}}_{j} - \textit{\textbf{b}}_{\langle j \rangle})$, i.e., $\tilde{\Delta}_{\textit{\textbf{a}}_j-\textit{\textbf{b}}_j}$.

\item{Effect size} for a given feature is the median  the vector derived from $\Delta_{\textit{\textbf{a}}_j-\textit{\textbf{b}}_j} / \Delta_{\textit{\textbf{a}}_j\lor \textit{\textbf{b}}_j}$, and is thus a standardized difference between the distributions in $\textit{\textbf{a}}_{j}$ and $\textit{\textbf{b}}_{j}$.
\end{itemize}

\subsection*{Alternative denominators}

The starting point for the alternative denominators is S, the $n$ samples by $D$ features matrix of counts. The data are clr transformed using Equation \ref{eq:CLR} sample-wise with a uniform prior of 0.5 to give a new matrix L. 

The \emph{IQLR} (interquartile log-ratio) transformation uses as the denominator for the *LR those features with `typical' variance across all samples. These are chosen as the intersect of the indices of the features that exhibit within-group variance within the interquartile range, these indices are retained to the give interquartile-variance feature \textit{IQVF} subset of the D features.
The geometric mean of the $\mathit{IQVF}$ set is used in the denominator to calculate a log-ratio for each sample vector $\bf{x}_i$ in matrix S:

\begin{equation}
\bf{x}_{i, \mathit{IQLR}} = log  \big( \frac{\bf{x}_{i,j=1 \dots D}}{G(\mathit{IQVF})}   \big)_{}
\label{eq:iqlr}
\end{equation}

The \emph{LVHA} (low variance high abundance log-ratio) transformation uses as the denominator for the *LR those features that have low variance and high relative abundance in each group. These are chosen as the intersect of the indices of the features that exhibit within-group variance below the first quartile and relative abundance above the third quartile on a per-group basis. The vector $\bf{v}_a$ is calculated as in the IQLR, except it is calculated group-wise. A second vector $\bf{rab}_a$ is also calculated group-wise from L by calculating the mean group-wise clr value of each feature. For group A, this is: $\mathit{LVHA}_a = \bf{v}_a < \bf{v}_{a,Q1} \cap \overline{L_a }> \bf{rab}_{a, Q3}$, and so on for other groups. The final set of LVHA indices is $\mathit{LVHA}_a \cap \mathit{LVHA}_b$ if there are two groups.

The geometric mean of the $\mathit{LVHA}$ set is used in the denominator to calculate a log-ratio for each sample vector $\bf{x}_i$ in matrix S:

\begin{equation}
\bf{x}_{i, \mathit{LVHA}} = log  \big( \frac{\bf{x}_{i,j=1 \dots D}}{G(\mathit{LVHA})}   \big)_{}
\label{eq:vale}
\end{equation}

\subsubsection*{The NZLR}

This transformation uses as the denominator for the *LR those features that are non-zero in a group. The *LR is calculated using a different set of indices for each group. The indices of non-zero features in each group are retained $\bf{v}_a = min(\mathrm{S}_{1 \ldots i_a}, 1 \ldots D) > 0;\bf{v}_b = min(\mathrm{S}_{(i_a+1) \ldots n}, 1 \ldots D) > 0 $ and used group wise

Now the features in group A have their log-ratio computed using the non-zero features in the group as the denominator, and likewise for group B. Thus, the transformed vectors in group A are:

\begin{equation}
\bf{x}_{ia, \mathit{NZLR}} = log \big( \frac{x_{1 \ldots i_a,_{j=1 \dots D}}}{G(\mathit{\bf{v}_a})} \big).\label{eq:iqlr}
\end{equation}

Similarly, the vectors in group B are transformed using as the denominator the $G(\mathit{\bf{v}_a})$ of the set of non-zero features in group B. 


\subsubsection*{The log median}

This transformation uses as the denominator the median of the clr-transformed values rather than the geometric mean. 
\begin{equation}
\bf{x}_{i,MED} = log({x_{i,j=1 \dots D}}) - \mathrm{MED}(log(x_i))
\label{eq:iqlr}
\end{equation}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Backmatter begins here                   %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{backmatter}

\section*{Declarations} 
\subsection*{Ethics approval and consent to participate}
All data used in this publication was 
\subsection*{Consent for publication}

\subsection*{Availability of data and material}
All data used in this publication are publicly available. The raw data for the yeast genome was drawn from the reference \em{Saccharomyces cerevisiae} genome at: https://www.ncbi.nlm.nih.gov/genome/?term=txid4932. The raw data for Figure 5 was obtained from : https://www.ebi.ac.uk/metagenomics/studies/MGYS00001863. All R scripts for figure generation and analysis are located on a public GitHub repository at: 
\subsection*{Competing interests}
 The authors declare that they have no competing interests.
  
\subsection*{Funding}
This work was supported by a grant from the Natural Sciences and Engineering Research Council of Canada grant RGPIN-2015-03878 to GBG

\section*{Author's contributions}
    Designed the experiments GBG, JRW, BLG. Generated the meta-transcriptome dataset JM, GBG. Developed and applied corrections BLG, JRW, GBG, JM. Wrote the manuscript, GBG. All authors have read and approved the manuscript.

\subsection*{Acknowledgements}
  Text for this section \ldots
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                  The Bibliography                       %%
%%                                                         %%
%%  Bmc_mathpys.bst  will be used to                       %%
%%  create a .BBL file for submission.                     %%
%%  After submission of the .TEX file,                     %%
%%  you will be prompted to submit your .BBL file.         %%
%%                                                         %%
%%                                                         %%
%%  Note that the displayed Bibliography will not          %%
%%  necessarily be rendered by Latex exactly as specified  %%
%%  in the online Instructions for Authors.                %%
%%                                                         %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% if your bibliography is in bibtex format, use those commands:
\bibliographystyle{bmc-mathphys} % Style BST file (bmc-mathphys, vancouver, spbasic).
\bibliography{bmc_article.bib}      % Bibliography file (usually '*.bib' )
% for author-year bibliography (bmc-mathphys or spbasic)
% a) write to bib file (bmc-mathphys only)
% @settings{label, options="nameyear"}
% b) uncomment next line
%\nocite{label}

% or include bibliography directly:
% \begin{thebibliography}
% \bibitem{b1}
% \end{thebibliography}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                               %%
%% Figures                       %%
%%                               %%
%% NB: this is for captions and  %%
%% Titles. All graphics must be  %%
%% submitted separately and NOT  %%
%% included in the Tex document  %%
%%                               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%
%% Do not use \listoffigures as most will included as separate files

\section*{Figures}

\begin{figure}[h!]
%\includegraphics[width=6in]{Fig_1.pdf}
\caption{\csentence{Effect plots of simulated asymmetric data illustrates the problem.} The effect plots show the difference between two conditions in simulated RNA-seq data with 1000 genes where 40 genes are modelled to have true difference between groups. Each point is a feature (gene) and they are coloured in black if not different between groups, red if identified as being statistically significantly different between groups, and red with a blue circle if they are one of the 40  genes modelled to be  true positives. The red points in the top right quadrant are the genes modelled to be asymmetrically variable between groups. These are also true positive features, but are not part of the initial modelled true positives. The inset histograms show the distribution of the differences between groups as calculated by ALDEx2, and the vertical line shows a difference of 0. These x-axis of the histograms are truncated to show only differences near the midpoint.}
\label{Fig:f1a}
\end{figure}

\begin{figure}[h!]
%\includegraphics[width=6in]{Fig_2.pdf}
\caption{\csentence{Effect plots of simulated asymmetric data with transformations that can result in a more accurate centring of the data.} Denominators were chosen for ALDEx2 using the iqlr, non-zero, lvha, or median option. The user defined denominator was 100 randomly chosen features known not to be different between groups. Points are coloured as in Figure \ref{Fig:f1a}, with the points used for the denominator in each case coloured in orange.}
\label{Fig:f2a}
\end{figure}

\begin{figure}[h!]
% \includegraphics[width=4in]{Fig_failure.pdf}
\caption{\csentence{The behaviour of each transformations for datasets with varying sparsity.} Each point represents the median between condition difference for a given transformation in a dataset with a specified sparsity. Points closer to the location y=0 are favourable. The CLR transformation fails as soon as asymmetric sparsity is introduced. The IQLR and LVHA transformations are effective on datasets with up to 25\% asymmetric sparsity from zeroes or extreme count features. The NZLR transformation is effective on datasets with up to 50\% sparsity, but the asymmetry must be from zeroes exclusively. Replacing the geometric mean with the median in Equation \ref{eq:CLR}, is an improvement, but results in a generally small shift in midpoint. The user defined correction was not applied as it is trivial to identify one or more invariant features in modelled data regardless of the percent sparsity.}
\label{Fig:failure}
\end{figure}

\begin{figure}[!t]
%\includegraphics[width=5in]{Fig_ones.pdf}
\caption{\csentence{The behaviour of each transformations for datasets with varying 2\% asymmetry where the asymmetric count value is 1.} The top left panel shows that it is not sparsity that is the problem, but rather the asymmetry  between groups since an asymmetry caused by a count of 1 also induces false positive identifications, shown in red below the dashed line. Both the IQLR and the LVHA transformations are able to centre the data appropriately. However, the zero-adjustment method fails because the problem is not sparsity but low counts.}
\label{Fig:ones}
\end{figure}

\begin{figure}[h!]
%\includegraphics[width=5in]{mgnify.pdf}
\caption{\csentence{Sparsity and asymmetry in a meta-transcriptome dataset of vaginal samples.}  The top left panel (denom=all) shows an effect plot of the data using the CLR values. Each point is a SEED function \cite{Mitra:2011,Macklaim:2018aa} and they are coloured in light brown if no sample contains a 0 value (non-sparse), dark brown if at least one sample contains a 0 count, blue if annotated as an ribosomal protein or magenta if annotated as a glycolytic function. The median displacement of the ribosomal and glycolytic functions from 0 is given in the top left of the plot. The data were then adjusted using the IQLR, LVHA, or a set of user-defined functions. In this case the user-defined functions were those annotated as ribosomal proteins in the SEED output. All three corrections place the ribosomal protein functions and glycolytic functions closer to zero, as desired, but the asymmetry is best addressed by the LVHA  adjustment.  }
\label{Fig:bv}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                               %%
%% Additional Files              %%
%%                               %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Additional Files}
  \subsection*{Additional file 1 --- Disp-v-Abund.pdf}
    plot of dispersion vs abundance for two data types. 

  \subsection*{Additional file 2 --- Reference PDF file}
    Reference PDF file


\end{backmatter}
\end{document}
